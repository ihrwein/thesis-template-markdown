# Correlation
Logs contain a lot of data which stay unprocessed because of the lack of proper
tools and softwares. I try to address this problem by writing a log parser and correlation
library as part of my Master Thesis.  

My correlation library is designed to be used as a building block of a bigger log management
software, therefore its configuration is easily parsed and generated by
machines. It can execute actions when one of the trigger conditions met:
* specific message types are received and a timeout expired between two event arrivals,
* specific message types are received till a timeout expires,
* the first or the last message is specified and the middle ones can come in any order,
* maximum number of events are grouped.

Nevertheless, messages can be grouped by not just their types (like SSH
login/logout) but by their additional key-value pairs. That's the way to send
an e-mail when a specific user logged in via SSH and read her mail.

I cannot describe the whole library in some pages, but I can shed some light on
the most interesting parts. One of them is the event handling/dispatching logic
and the asynchronous communication between threads.

## Event handling

There are two event types involved in the correlation: message and timer events.
Message events are just processed log messages. This means they bear an UUID and
several key-value pairs. Let's say we have the following SSH log:
```
Jun 25 14:09:58 servername sshd[26665]: Accepted publickey for joe from\
10.30.0.35 port 40685 ssh2
```

We can easily assign an UUID for this message type. After parsing we have the
following key-value pairs:
```
uuid=e4a44aec-d317-4ed8-bb2a-b1d66a223cda
date=Jun 25 14:09:58
hostname=servername
authtype=publickey
username=joe
fromhost=10.30.0.35
port=40685
protocol=ssh2
```

Timer events continuously arrive within a specific interval. They update the open
correlation contexts and when a context's timeout expires or an other close condition
is being met the context's state gets closed.

There is a design pattern to work with events, it's called Reactor
pattern. I use it to dispatch the events based on their types to their
handlers. The final design went through the following iterations:

1. I use language elements to dispatch the events based on their types (like the `match` statement).

    It's the simplest approach but doesn't scale well. The message events are
    dispatched to all context instances even for those which are not interested
    in them.

2. An unusual mixture of the Reactor pattern with the Observer (never implemented).

    The events are dispatched by the Reactor but the event handlers are
    actually observers of the context instances. This idea was dismissed
    because handling an event isn't equal to acting on state changes.

3. There is a Reactor but the event handlers are organized into hierarchies.

    The first hierarchy is handled by the Reactor itself. The second is only
    present in case of message events: they can be dispatched by their name or their
    type.  The contexts have to be shared between the timer and message event
    handlers, because they have to operate on the same data. Therefore, the
    contexts don't have a specific owner and they had to put into
    `Rc<RefCell<T>>` types. `Rc<T>` is a lightweight reference counted pointer
    type but it cannot yield mutable data.  The actual context instances are
    reside in `RefCell<T>` instances which provide so called "interior
    mutability". Their borrowing semantics are checked in runtime, so mutable data can be
    shared through them.

    Although this approach worked, the lot of `Rc<RefCell<T>>` variables looked
    like an awful solution. They are very similar of an "RWlock" in a single
    threaded application. Nevertheless, an extra `EventHandler` trait
    was needed to handle the different types of contexts, so finally, I had
    to wrap every context into a variable like
    `Rc<RefCell<Box<EventHandler<InternalRequest>>>>`.
    

4. A clear Reactor pattern.

I will describe the third approach in more details but first, lets look at the
Reactor pattern.

### Reactor pattern

The Reactor pattern synchronously dispatches concurrently arriving events. The
dispatcher demultiplexes the requests and calls the associated event handlers.

The Reactor pattern has the following components:

* `EventHandler`: receives events to execute a handler function.
* `EventDemultiplexer`: produces events when one can be handled in a synchronous way.
* `Event`: every event types must implement the `Event` trait. They provide
   information about their associated handlers.
* `Reactor`:
 * handles registering and removing of event handlers,
 * dispatches events to their associated handlers.

#### Implementation in Rust

The Reactor pattern can be defined as the following code snippet:

```Rust
pub trait Event {
    type Handler;
    fn handler(&self) -> Self::Handler;
}

pub trait EventHandler<T: Event> {
    fn handle_event(&mut self, event: T);
    fn handler(&self) -> T::Handler;
}

pub trait EventDemultiplexer {
    type Event: Event;
    fn select(&mut self) -> Option<Self::Event>;
}

pub trait Reactor {
    type Event: Event;
    fn handle_events(&mut self);
    fn register_handler(&mut self,
                        handler: Box<EventHandler<Self::Event>>);
    fn remove_handler_by_handler(&mut self,
            handler: &<<Self as Reactor>::Event as Event>::Handler);
}
```

##### The `Event` trait

The `Event` trait has to be implemented by every event type dispatched
by the `Reactor`. The trait specifies the `Handler` associated type which lets the
implementor define the output type of the `handler()` method. Therefore, every
`Event` instance can be asked about its handler.

##### The `EventHandler` trait

Every event handler has to implement this trait. The `handle_event()` method is
a good example of Rust's trait based generics. The `T` generic type parameter
can be any type which implements the `Event` trait. Therefore, `handle_event()`
can receive only `Event` implementations.

The `handler()` method on `EventHandler` returns the type/value for which this
instance is responsible to handle.

##### The `EventDemultiplexer` trait

The `EventDemultiplexer` defines the `Event` associated type which has the
`Event` trait as a bound.  It's `select()` method emits an
`Option<Self::Event>` like an iterator. If its value is `None`, that means there
won't be new events produced.

The `Event` associated type with the trait bound restricts the set of the
"emittable" event types for those, which implement the `Event` trait.

##### The `Reactor` trait

The `Reactor` trait is responsible for registering and removing event handlers.
It defines an `Event` associated type with the `Event` trait as a bound similar
to the `EventDemultiplexer` trait.

The `Reactor` is supposed to have an event loop where it waits for events from
the `EventDemultiplexer`. When an event arrives the reactor checks the event's
`handler()` method and based on the result calls the appropriate registered `EventHandler`.

The simplest methods are for registering and removing `EventHandler` instances.
`register_handle()` takes an event handler and inserts it into a map where the key
is the handler and actually the value is the event handler.

The `remove_handler_by_handler()` method cannot work this way. If you want to
remove an item from the map you must have a mutable reference to it but if you
have a reference to the `EventHandler` that's impossible with Rust's borrowing
rules. Therefore, this function takes a reference to the handler (which can be
copied).

As I said earlier the contexts has to be shared between the timer and message
event handlers. I created a specific `ContextMap` `struct` which supports
looking up handlers by message names/types or iterating over all contexts.

I altered slightly the pure Reactor pattern to enable to use shared data.
This means, that the `EventHandler` `handle_event()` method now takes a 
`T` type parameter and my Reactor implementation passes its `ContextMap` object
to the event handlers.

I think it's worth to look at the implementation of the `Reactor` trait in my
case:

```Rust
impl Reactor<ContextMap> for RequestReactor {
    type Event = InternalRequest;
    fn handle_events(&mut self) {
        while !self.exit_condition.is_active() {
            if let Some(request) = self.demultiplexer.select() {
                trace!("RequestReactor: got event");
                let handler = request.handler();
                if let Some(handler) = self.handlers.get_mut(handler) {
                    handler.handle_event(request, &mut self.context_map);
                } else {
                    trace!("RequestReactor: no handler found for event");
                }
            } else {
                break;
            }
        }
    }
    fn register_handler(&mut self,
            handler: Box<EventHandler<Self::Event, ContextMap>>) {
        self.handlers.insert(handler.handler(), handler);
    }
    fn remove_handler_by_handler(&mut self, handler: &RequestHandler) {
        self.handlers.remove(handler);
    }
}
```

The `handle_events()` method defines the internal event loop of the Reactor.
Until the `exit_condition` is activated, it waits for events from the
demultiplexer. When an event arrives it takes its handler and looks up the
appropriate event handler instance to call its `handle_event()` method. It
lends its `context_map` member so the event handler can update the contexts'
states.

## Threads and channels

We know that Moore's law holds today as much as it was observed fifty years ago. We can't
make processors which operate on higher frequencies so the most usual way to speed up
softwares is to scale them on multiple CPU cores using threads (or using GPGPUs, etc.).

Writing multithreaded programs is not easy. It requires extra effort to design
a software which is not error prone or doesn't have synchronization problems.

The Rust language is designed to safely work in multithreaded environments.
I'll describe the core concepts, how Rust accomplishes its safety in this area.

Rust has the `Sync` trait for marking whether a type can be safely shared
between threads:
> "a type T is Sync if &T is thread-safe."

The primitive types are inherently `Sync` and the simple aggregate types are also
`Sync`. The `Rc<T>` type is not `Sync`, because the reference counting is not
atomic.

The `Send` marker trait enables safely sending types across thread boundaries.

Rust offers synchronization primitives, such as mutexes or atomically reference
counted pointers (`Arc<T>`). Using `Arc<T>` pointers can easily lower the performance
because caches has to be synchronized among CPU cores.

The preferred way of thread communication in Rust is using the so called
`channels`.  They provide FIFO queue communication primitives between threads in
a safe way. Channels can work in a synchronous or asynchronous way. In the
first case the sender blocks till the message is read from the channel. The
asynchronous case immediately returns from `send()` regardless of whether the
receiver read the data. An asynchronous channel conceptually has an infinite
buffer.

### Threads in the library

The previously described Reactor runs in its own thread. Running several
Reactor instances (each one in its own thread) can almost linearly increase the
throughput of the library.

