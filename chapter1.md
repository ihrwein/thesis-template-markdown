# Rust language bindings in syslog-ng

This document summarizes my work during my internship at Balabit. I
worked on areas related to my Master Thesis but they are distinct from it. Most
of my task was to integrate my log parser and correlation libraries to the
`syslog-ng` log management software.

The subject of my thesis is to create a log parsing and correlation library.
My internship focused on creating Rust bindings for syslog-ng and investigate
the Reactor design pattern in Rust.

In the first chapter I describe how the Reactor pattern can be implemented in
Rust.  The reactor runs in its own thread so I wrote about threads and channels
as well.

The second chapter goes into details of the interaction between the C and Rust
languages. This chapter contains information about how function calls work between the
two languages. It also describes the general concept of language bindings in
syslog-ng and its module system.

Finally, the third chapter presents several iterations of the design of the
Rust language bindings.
# Correlation
Logs contain a lot of data which stay unprocessed because of the lack of proper
tools and softwares. I try to address this problem by writing a log parser and correlation
library as part of my Master Thesis.  

My correlation library is designed to be used as a building block of a bigger log management
software, therefore its configuration is easily parsed and generated by
machines. It can execute actions when one of the trigger conditions met:
* specific message types are received and a timeout expired between two event arrivals,
* specific message types are received till a timeout expires,
* the first or the last message is specified and the middle ones can come in any order,
* maximum number of events are grouped.

Nevertheless, messages can be grouped by not just their types (like SSH
login/logout) but by their additional key-value pairs. That's the way to send
an e-mail when a specific user logged in via SSH and read her mail.

I cannot describe the whole library in some pages, but I can shed some light on
the most interesting parts. One of them is the event handling/dispatching logic
and the asynchronous communication between threads.
## Event handling

There are two event types involved in the correlation: message and timer events.
Message events are just processed log messages. This means they bear an UUID and
several key-value pairs. Let's say we have the following SSH log:
```
Jun 25 14:09:58 servername sshd[26665]: Accepted publickey for joe from 10.30.0.35 port 40685 ssh2
```

We can easily assign an UUID for this message type. After parsing we have the
following key-value pairs:
```
uuid=e4a44aec-d317-4ed8-bb2a-b1d66a223cda
date=Jun 25 14:09:58
hostname=servername
authtype=publickey
username=joe
fromhost=10.30.0.35
port=40685
protocol=ssh2
```

Timer events continuously arrive within a specific interval. They update the open
correlation contexts and when a context's timeout expires or an other close condition
is being met the context's state gets closed.

There is a design pattern to work with events, it's called Reactor
pattern. I use it to dispatch the events based on their types to their
handlers. The final design went through the following iterations:

1. I use language elements to dispatch the events based on their types (like the `match` statement).

    It's the simplest approach but doesn't scale well. The message events are
    dispatched to all context instances even for those which are not interested
    in them.

2. An unusual mixture of the Reactor pattern with the Observer (never implemented).

    The events are dispatched by the Reactor but the event handlers are
    actually observers of the context instances. This idea was dismissed
    because handling an event isn't equal to acting on state changes.

3. There is a Reactor but the event handlers are organized into hierarchies.

    The first hierarchy is handled by the Reactor itself. The second is only
    present in case of message events: they can be dispatched by their name or their
    type.  The contexts have to be shared between the timer and message event
    handlers, because they have to operate on the same data. Therefore, the
    contexts don't have a specific owner and they had to put into
    `Rc<RefCell<T>>` types. `Rc<T>` is a lightweight reference counted pointer
    type but it cannot yield mutable data.  The actual context instances are
    reside in `RefCell<T>` instances which provide so called "interior
    mutability". Their borrowing semantics are checked in runtime, so mutable data can be
    shared through them.

    Although this approach worked, the lot of `Rc<RefCell<T>>` variables looked
    like an awful solution. They are very similar of an "RWlock" in a single
    threaded application. Nevertheless, an extra `EventHandler` trait
    was needed to handle the different types of contexts, so finally, I had
    to wrap every context into a variable like
    `Rc<RefCell<Box<EventHandler<InternalRequest>>>>`.
    

4. A clear Reactor pattern.

I will describe the third approach in more details but first, lets look at the
Reactor pattern.

### Reactor pattern

The Reactor pattern synchronously dispatches concurrently arriving events. The
dispatcher demultiplexes the requests and calls the associated event handlers.

The Reactor pattern has the following components:
* `EventHandler`: receives events to execute a handler function.
* `EventDemultiplexer`: produces events when one can be handled in a synchronous way.
* `Event`: every event types must implement the `Event` trait. They provide
   information about their associated handlers.
* `Reactor`:
 * handles registering and removing of event handlers,
 * dispatches events to their associated handlers.

#### Implementation in Rust

The Reactor pattern can be defined as the following code snippet:

```Rust
pub trait Event {
    type Handler;
    fn handler(&self) -> Self::Handler;
}

pub trait EventHandler<T: Event> {
    fn handle_event(&mut self, event: T);
    fn handler(&self) -> T::Handler;
}

pub trait EventDemultiplexer {
    type Event: Event;
    fn select(&mut self) -> Option<Self::Event>;
}

pub trait Reactor {
    type Event: Event;
    fn handle_events(&mut self);
    fn register_handler(&mut self, handler: Box<EventHandler<Self::Event>>);
    fn remove_handler_by_handler(&mut self, handler: &<<Self as Reactor>::Event as Event>::Handler);
}
```

##### The `Event` trait

The `Event` trait has to be implemented by every event type dispatched
by the `Reactor`. The trait specifies the `Handler` associated type which lets the
implementor define the output type of the `handler()` method. Therefore, every
`Event` instance can be asked about its handler.

##### The `EventHandler` trait

Every event handler has to implement this trait. The `handle_event()` method is
a good example of Rust's trait based generics. The `T` generic type parameter
can be any type which implements the `Event` trait. Therefore, `handle_event()`
can receive only `Event` implementations.

The `handler()` method on `EventHandler` returns the type/value for which this
instance is responsible to handle.

##### The `EventDemultiplexer` trait

The `EventDemultiplexer` defines the `Event` associated type which has the
`Event` trait as a bound.  It's `select()` method emits an
`Option<Self::Event>` like an iterator. If its value is `None`, that means there
won't be new events produced.

The `Event` associated type with the trait bound restricts the set of the
"emittable" event types for those, which implement the `Event` trait.

##### The `Reactor` trait

The `Reactor` trait is responsible for registering and removing event handlers.
It defines an `Event` associated type with the `Event` trait as a bound similar
to the `EventDemultiplexer` trait.

The `Reactor` is supposed to have an event loop where it waits for events from
the `EventDemultiplexer`. When an event arrives the reactor checks the event's
`handler()` method and based on the result calls the appropriate registered `EventHandler`.

The simplest methods are for registering and removing `EventHandler` instances.
`register_handle()` takes an event handler and inserts it into a map where the key
is the handler and actually the value is the event handler.

The `remove_handler_by_handler()` method cannot work this way. If you want to
remove an item from the map you must have a mutable reference to it but if you
have a reference to the `EventHandler` that's impossible with Rust's borrowing
rules. Therefore, this function takes a reference to the handler (which can be
copied).

As I said earlier the contexts has to be shared between the timer and message
event handlers. I created a specific `ContextMap` `struct` which supports
looking up handlers by message names/types or iterating over all contexts.

I altered slightly the pure Reactor pattern to enable to use shared data.
This means, that the `EventHandler` `handle_event()` method now takes a 
`T` type parameter and my Reactor implementation passes its `ContextMap` object
to the event handlers.

I think it's worth to look at the implementation of the `Reactor` trait in my
case:

```Rust
impl Reactor<ContextMap> for RequestReactor {
    type Event = InternalRequest;
    fn handle_events(&mut self) {
        while !self.exit_condition.is_active() {
            if let Some(request) = self.demultiplexer.select() {
                trace!("RequestReactor: got event");
                if let Some(handler) = self.handlers.get_mut(&request.handler()) {
                    handler.handle_event(request, &mut self.context_map);
                } else {
                    trace!("RequestReactor: no handler found for event");
                }
            } else {
                break;
            }
        }
    }
    fn register_handler(&mut self, handler: Box<EventHandler<Self::Event, ContextMap>>) {
        self.handlers.insert(handler.handler(), handler);
    }
    fn remove_handler_by_handler(&mut self, handler: &RequestHandler) {
        self.handlers.remove(handler);
    }
}
```

The `handle_events()` method defines the internal event loop of the Reactor.
Until the `exit_condition` is activated, it waits for events from the
demultiplexer. When an event arrives it takes its handler and looks up the
appropriate event handler instance to call its `handle_event()` method. It
lends its `context_map` member so the event handler can update the contexts'
states.

### The `ContextMap` type

The `ContextMap` type is responsible for storing all context instances and
providing querying functionality in the same time. The contexts can be iterated
over or one can ask the question which contexts are subscribed to a particular
message type.

All of this is achieved by building a simple index on an array of context
instances which is depicted on the following diagram.

![ContextMap](context_map.svg)

Here we have three message types: `A`, `B` and `C`. The `ctx1` and `ctx2` contexts are subscribed to `A`, `ctx3` to `B` and so on.

The `ContextMap` consist of two data structures:
* an array of context instances (`Contexts` on the diagram)
* an associative array (map) of message identifiers and vector of integer
  numbers (`Index` on the diagram)

Every time a context is inserted into the `ContextMap` it is appended to the
`Contexts` array.  Its position in the array will be its "identifier". If the
context should subscribe to message types, then their identifier will be
inserted into the `ContextMap`. The value can be a new vector with a single
number (the position) or an existing vector in which case the number is
appended to the end.

Every event handler uses the `ContextMap` in a slightly different way. The 
`TimerEventHandler` iterates over all contexts while the `MessageEventHandler`
queries by the message identifiers to update the subscribed contexts.

The iteration method cannot use the standard `Iterator` trait because any yielded reference lasts as long as the iterator itself, rather than as long as the borrow.

I had to yield `&mut
Context` instances which means this approach cannot work (multiple mutable borrows from the same object). Instead, I use a
streaming iterator "pattern" where lifetime of the yielded items are not tied
to the iterator but to the borrow.

A simplified version of this iterator is shown in the next listing:

```Rust
pub trait StreamingIterator {
    type Item;
    fn next<'a>(&'a mut self) -> Option<&'a mut Self::Item>;
}

pub struct Iterator<'a> {
    ids: &'a Vec<usize>,
    pos: usize,
    contexts: &'a mut Vec<Context>
}

impl<'a> StreamingIterator for Iterator<'a> {
    type Item = Context;
    fn next(&mut self) -> Option<&mut Context> {
        if let Some(id) = self.ids.get(self.pos) {
            self.pos += 1;
            self.contexts.get_mut(*id)
        } else {
            None
        }
    }
}
```

The most notable part of the code is the `next()` method:
```Rust
fn next<'a>(&'a mut self) -> Option<&'a mut Self::Item>;
```

### Event handlers
There are two types of events: message and timer. There is a third one used
only for control purposes. These events needs to be handled differently. Timer
events needs to be handled by every event handler to update their internal timers.
Message events concerns only those handlers which are "subscribed" for those
message types. Nevertheless, messages can be grouped together by their
key-value pairs which makes this case more complex. The control message type is
for synchronizing stopping threads in a safe and reliable way.

#### Exit event handler

The event reactor runs in its own thread and receives the events via
asynchronous channels. The events may trigger actions which may send data to
the outside.  These channels have high throughput, but lack of something: when
one end gets closed the internal buffer becomes inaccessible. This means that
we need a way to make sure that every data is processed from the channel.

I defined a simple "Exit protocol" which ensures that there is no data
left in the internal buffer. The protocol begins with sending an `Exit` event
through the input channel of the reactor. It dispatches it to the
`ExitEventHandler` which increments a counter and sends an `Exit` event through
its output channel.

This event is looped back to the reactor which dispatches it again to the proper
event handler. The internal counter reaches the `2` value and the reactor's
loop condition is set to `false`, which means the thread will successfully
stop.

The outer thread will consume every data from the channel. The last one
will be the `Exit` event sent by the `ExitEventHandler`. 

#### Timer event handler

Timer events are forwarded to every context instances. It uses the `ContextMap`
type to iterate over all context instances and update their timers.

#### Message event handler

Message events are forwarded to the subscribed contexts. A message can open or
close a context's state. When a state is open all messages are appended to
the state.

## Threads and channels

We know that Moore's law holds today as much as it was observed fifty years ago. We can't
make processors which operate on higher frequencies so the most usual way to speed up
softwares is to scale them on multiple CPU cores using threads (or using GPGPUs, etc.).

Writing multithreaded programs is not easy. It requires extra effort to design
a software which is not error prone or doesn't have synchronization problems.

The Rust language is designed to safely work in multithreaded environments.
I'll describe the core concepts, how Rust accomplishes its safety in this area.

Rust has the `Sync` trait for marking whether a type can be safely shared
between threads:
> "a type T is Sync if &T is thread-safe."

The primitive types are inherently `Sync` and the simple aggregate types are also
`Sync`. The `Rc<T>` type is not `Sync`, because the reference counting is not
atomic.

The `Send` marker trait enables safely sending types across thread boundaries.

Rust offers synchronization primitives, such as mutexes or atomically reference
counted pointers (`Arc<T>`). Using `Arc<T>` pointers can easily lower the performance
because caches has to be synchronized among CPU cores.

The preferred way of thread communication in Rust is using the so called
`channels`.  They provide FIFO queue communication primitives between threads in
a safe way. Channels can work in a synchronous or asynchronous way. In the
first case the sender blocks till the message is read from the channel. The
asynchronous case immediately returns from `send()` regardless of whether the
receiver read the data. An asynchronous channel conceptually has an infinite
buffer.

### Threads in the library

The previously described Reactor runs in its own thread. Running several
Reactor instances (each one in its own thread) can almost linearly increase the
throughput of the library.
# Language bindings in syslog-ng

Syslog-ng is a log management software. It is written in C which offers high
performance but makes the development much harder: it can be learned easily but
writing good code is very hard. If a system administrator needs a feature he cannot
develop that without C programming experience. Also, legacy codes needs an
extra care because a little change in one place can easily alter the execution
of other parts. Nevertheless, they are very likely to be able to write Python
or Perl code in some level.

Today's technologies are focused around Big Data projects. Hadoop, Elastic Search,
Kafka are all written in Java. Their official libraries are maintained while
the other language bindings aren't so feature rich or not maintained so well.

Rust is different from the other mentioned languages in that, it is compiled
into native code. Rust's runtime isn't bigger than the C's one and doesn't
support garbage collection. The language is built to support compatibility
with the existing C libraries and has its novel ownership and borrowing rules
which ease to write safe and fast programs.
## General concept

The general concept is built on the following aspects:
* syslog-ng-core is written in C and offers services to modules,
* a module can be written in any language which has bindings for syslog-ng.

`syslog-ng-core` can be used for message processing, filtering, multiplexing
and demultiplexing. Modules provide additional features such as the ability
to send messages into an Elastic cluster or parsing the messages with Python
functions. 

Python and Java are not native languages. They have to use explicitly written
bindings to work. These bindings resides in their own modules and are able to dynamically
load several Java or Python plugins. For example a Java destination can be loaded
if the user knows its class name and sets the proper `classpath`.
## syslog-ng's module system

syslog-ng loads its modules from shared object files (`.so`). They are under
the `$prefix/lib/syslog-ng` directory. A module can contain zero or more plugins.

Every module has to export some variables and functions. The `module_info` (of
type `ModuleInfo`) constant `struct` contains some basic information about the
module itself ( `name`, `description`, etc.) and a pointer (`plugins`) to a
`Plugin` array. A `Plugin` has a `name`, a `type` (parser, filter, etc.) and a
`parser` field which points at a `CfgParser` instance. The `CfgParser` `struct`
contains a function pointer to a generated grammar parser function and some
fields as well.

Loading a plugin is requested by syslog-ng's configuration grammar. When it
encounters a valid identifier which is not defined as a keyword it tries to
find a plugin with that name and with the type of the actual context in the
grammar. If it finds a plugin, it loads its contents and calls the grammar's
parser function.

## `*-sys` crates

Rust and Cargo has a convention about how to deal with crates which provide
language bindings for native libraries. These crates should be named like
`foo-sys` where the name of the native library is `libfoo`.

`sys` crates should provide only the low level bindings, the higher level
code should go into other crates.

Using `sys` crates simplifies the linking and makes possible to easily create
higher level crates.
# The first version of Rust bindings in syslog-ng

I created bindings for filters and parsers. Filters are the simplest components
of syslog-ng, so they were good subjects to start with. The final result supports
only parsers, because they can work as filters and my libraries can be integrated as
parsers.
## The first version of Rust bindings in syslog-ng

I created bindings for filters and parsers. Filters are the simplest components
of syslog-ng so they were good subjects to start with. 

### Filters

Filters can filter out the incoming data. The `ParserRust` class is inherited
from the `FilterExprNode` class. It registers its methods as callbacks on its
`super` which forwards the calls into a `RustFilterProxy` object. That holds
a pointer to a `RustFilter` trait object.

The `RustFilter` traits definition is as follows:

```Rust
pub trait RustFilter {
    fn init(&mut self, _: &GlobalConfig) {}
    fn eval(&self, msg: &mut LogMessage) -> bool;
    fn set_option(&mut self, key: String, value: String);
}
```

The class diagram is depicted on the following picture.

![RustFilter](rust_filter.svg)

`FilterExprNode` and `FilterRust` are defined in `C` while `RustFilter`
and `RustFilterProxy` are defined in Rust.

Filters are not so important as parsers, because a parser can substitute filters
in many ways.

### Parsers

Parsers are able to parse messages into key-value pairs. The `ParserRust` class has a pointer to a
`RustParserProxy` object. `ParserRust` is defined in C while `RustParserProxy` is
a Rust object. 

The `RustParserProxy` has a `parser` pointer member which holds a `RustParser`
trait object. `ParserRust` registers its functions on its ancestor `LogPipe` as
callbacks.  Those functions forwards the execution through the `RustParserProxy`
pointer, which also forwards them to the trait object.

`RustParserProxy` is needed, because trait objects are behind a fat pointer.
They cannot be passed to the C side without wrapping them in a `struct`. The
`struct`'s memory representation is the same as it would be a C struct: the
`#[repr(C)]` attribute takes care about this.

The definition of the `RustParser` trait is the following:

```Rust
pub trait RustParser {
    fn init(&mut self) -> bool { true }
    fn set_option(&mut self, _: String, _: String) {}
    fn process(&mut self, msg: &mut LogMessage, input: &str) -> bool;
    fn boxed_clone(&self) -> Box<RustParser>;
}
```

The class diagram is depicted on the following picture.

![RustParser](rust_parser.svg)

## The current Rust bindings

The first design was simple but had some flaws:
1. there was one big `syslog-ng-rust-modules` library which contained all modules
  written in Rust,
2. a filter/parser didn't know its parent, it couldn't call its parent's
  functions,
3. `syslog-ng-sys` wasn't an independent crate and provided some
  higher level bindings.

The current Rust bindings solve these problems, but without the first version I
wouldn't be able to realize them at all. So the first binding version was a
necessary step towards the more usable and flexible bindings.

### Having `1:1` mapping between modules and Rust modules
The ideal solution for the first problem is having a 1:1 mapping between Rust
and C modules. This means that each Rust module has its own crate and the build
result is a `lib*.so` file which can be copied into syslog-ng's module
directory.

This solution introduces the following problems:
1. Every plugin has to have its own grammar:
 1. writing bindings for the grammar is a huge and tedious work,
 1. compiling the grammar needs well parameterized grammar generators,
 1. the grammar calls exported functions, their redeclarations look like boilerplate code.
1. The `module_info` `struct` has to be generated:
 1. module and plugin names are null terminated strings which cannot be created
    with Rust in static variables or constants,
 1. the `module_info` `struct` is expected to be static.
1. The code which connects Rust and C halves looks like boilerplate.

The first problem can be solved if syslog-ng creates a static library which
contains the generated grammar and the Rust modules link against this library.
Unfortunately, I discovered a
[bug](https://github.com/balabit/syslog-ng/issues/714) in syslog-ng's
plugin/grammar system which blocked this solution. After fixing It, I was able
to generate this static library, but it didn't work as expected. The problem
was, that this static library was linked into several shared libraries (each
one of them was a Rust module). The static library exported some public
symbols which were present in these shared libraries, so when syslog-ng opened
them the linker resolved these symbols only once. The result was, that only
the first loaded Rust module was effective, all the subsequently loaded modules
was mapped to the first one.

The solution was to force the compiler to generate hidden symbols which aren't
visible outside of the created library. If the object files are compiled with
the `-fvisibility=hidden` parameter, the
`__attribute__((visibility("hidden")))` attribute is applied to the
**non-extern** symbols. The `extern` functions (as well as the forward function
declarations) have to be marked explicitly with this attribute. Finally, the
static library doesn't export any public symbols but if it's linked into a
shared library, its undefined symbols are resolved from the shared library.

This static library references functions which has to be present in the final
`.so` library. These functions are my `proxy` functions in Rust:

* `native_parser_proxy_new()`: creates a new proxy instance,
* `native_parser_proxy_free()`: frees a proxy instance,
* `native_parser_proxy_clone()`: clones a proxy instance,
* `native_parser_proxy_set_option()`: sets a key-value configuration option on a proxy instance,
* `native_parser_proxy_init()`: initializes the proxy based on the previously set configuration options,
* `native_parser_proxy_process()`: parses an input string.

A Rust module defines these symbols so when the linker copies the static library
into the shared library, the symbols are resolved internally (hidden visibility).

The second problem can be solved if the Rust module generates a `module.c` file
with the `module_info` variable, then compiles it into a static library and
uses it for linking. This generation can be done with a build script which is
supported by Cargo. The `pkg-config` and `gcc` programs have already have
bindings so they can be used by the build script. I created a `create_module()` function
which does the module definition generation and compilation. Unfortunately,
compilation requires some macros to be defined which are not available
if syslog-ng is installed from a package. These macros are generated when syslog-ng
is configured via its `configure` script and placed in the `config.h` file. 
This file is not distributed with good reason: if it gets included into a third
application, it can overwrite the application's own macros. I solved this problem
by prefixing all generated macros with `SYSLOG_NG` (with using the `AX_PREFIX_CONFIG_H`
macro) and distributing `config.h` as `syslog-ng-config.h`.

The third problem is solved by moving all boilerplate code into a macro and a function.
I'll present them later, when the Rust half of the architecture is described.

### The Rust part

A single parser interface presents a problem, at least is Rust. Let's assume
we would like to create a parser, which requires its own configuration file (`F`),
an URL (`U`) and has two other optional parameters (`A` and `B`). By instinct,
we would map this parser into this struct definition:

```rust
struct DummyParser {
    F: ConfigurationFile,
    U: URL,
    A: Option<String>,
    B: Option<String>,
}
```

This definition clearly states, that `F` and `U` are required options and `A` and `B`
are optional ones. In Rust, when a struct is instantiated, all of its fields have to be initialized
with a valid value. `A` and `B` can get the `None` value, but what should happen with `F` and `U`?
Other languages, like `Java`, would use the `null` value there. We can also define them
as optional values:

```rust
struct DummyParser {
    F: Option<ConfigurationFile>,
    U: Option<URL>,
    A: Option<String>,
    B: Option<String>,
}
```

Everything is optional so we can instantiate the struct with only `None` values.
Let's see, how would a `parse()` call look like:

```rust
fn parse(&mut self, input: &str) -> bool {
    if let Some(f) = self.F.as_ref() {
        if let Some(u) = self.U.as_ref() {
            // do the parsing here
        } else {
            // ???
        }
    } else {
        // ???
    }
}
```

I marked the interesting lines with the `???` comment. We know, that when
`parse()` is called the parser should be initialized, but we must represent
the required fields with optional values, because of the initialization
process. This is really ugly, so I had to come up with something more clever.

I split the single parser interface into two halves. The first half handles
the initialization process and when everything is set, it builds the parser
instance in one step. The parser definition uses `Option<T>s` only
for the optional values.

The `ParserBuilder` trait is responsible for building a `Parser`
instance based on the configuration options. The definition of these traits
are as follows:

```rust
pub trait ParserBuilder: Clone {
    type Parser: Parser;
    fn new() -> Self;
    fn option(&mut self, name: String, value: String);
    fn parent(&mut self, _: *mut LogParser) {}
    fn build(self) -> Result<Self::Parser, OptionError>;
}

pub trait Parser: Clone {
    fn parse(&mut self, msg: &mut LogMessage, input: &str) -> bool;
}
```

Each parser should implement the `Parser` trait. It contains
only a `parse()` method, which parses an input string and returns the result
of the parsing.

`Parsers` are created by their corresponding `ParserBuilder` implementation.
They are instantiated without parameters and the configuration options are
set through the `option()` method. The `parent()` method sets the parent of
this parser, in fact it is a pointer to a C struct. It is generally not needed,
but there may be use-cases for accessing it from Rust in the future. The
`build()` method builds either a parser or returns an error and it consumes
itself in the process. Note, that Rust's type system constraints the type of
the built parser: a given builder can build only one specific parser type and
this constraint is built into the interface itself.

The missing piece is the type which actually forwards the calls from the
C side to the Rust parser instance. It is defined as follows:

```rust
#[repr(C)]
#[derive(Clone)]
pub struct ParserProxy<B> where B: ParserBuilder {
    pub parser: Option<B::Parser>,
    pub builder: Option<B>
}
```

It is generic over a B parameter, which must implement the `ParserBuilder`
trait.  Note, that the proxy knows the type of the parser field. This leads to
increased performance, because the method calls can be statically dispatched or
even inlined. If the parser has no size (like `struct Foo;`) the compiler can
further optimize the code.

I created a macro to generate the definitions of the `native_parser_proxy_*()`
functions. The `parser_plugin!` macro takes a `ParserBuilder` implementation as
its parameter and generates these functions, such as 

```rust
#[no_mangle]
pub extern fn native_parser_proxy_free(_: Box<ParserProxy<$name>>) {
}
```

The `$name` parameter is the name of the type which was passed to the `parser_plugin!` macro.

The `module_info` structure is generated in a build script. The `create_module()` function
is responsible for generating the module structure.

I split the Rust code into three separate crates:

* `syslog-ng-sys` contains the low level FFI bindings,
* `syslog-ng-common` contains the high level traits, such as `Parser`,
* `syslog-ng-build` contains the `create_module()` function.

The build process of a Rust module is as follows:
1. the Rust compiler (`rustc`) compiles the build script, then executes it:
 1. the build script looks for the `libsyslog-ng-native-connector.a` file (via `pkg-config`) and adds it to the linker search path,
 1. the build script generates a `module.c` file, compiles it into a `librust-module.a` file and adds it to the linker search path.
1. rustc compiles the parser implementation,
1. rustc expands the macro invocation into the `native_parser_proxy_*()` function,
1. rustc generates a `lib<name>.so` file.

The result is a shared library which can be immediately copied into syslog-ng's module directory.

![ProposedRustParser](current_parser.svg)

# Summary

I described the Reactor pattern and presented an implementation in Rust.  The
Reactor pattern is used in concurrent environments so I also described the
threads and channel concept in Rust.

My main task was to design and implement Rust language bindings for syslog-ng.
First, I presented the general concept of language bindings in syslog-ng, then
described its module system. Next, I showed how C and Rust can interact with
each other.

It took several iterations until I was content with the results. I described
the main iteration steps and presented the final result in more details.
